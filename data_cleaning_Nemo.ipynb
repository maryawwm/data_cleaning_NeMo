{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyHxZFpPVA7I",
        "outputId": "eb359fa5-b36f-4eae-cfa7-1025733a926d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data ...\n",
            "--2023-11-06 04:25:57--  https://dl.fbaipublicfiles.com/laser/WikiMatrix/v1/WikiMatrix.en-fa.tsv.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.173.166.48, 18.173.166.51, 18.173.166.74, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.173.166.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139938612 (133M) [application/gzip]\n",
            "Saving to: ‘data/WikiMatrix.en-fa.tsv.gz’\n",
            "\n",
            "data/WikiMatrix.en- 100%[===================>] 133.46M  35.5MB/s    in 3.9s    \n",
            "\n",
            "2023-11-06 04:26:02 (33.9 MB/s) - ‘data/WikiMatrix.en-fa.tsv.gz’ saved [139938612/139938612]\n",
            "\n",
            "---------------------\n",
            "Unzipping file ...\n",
            "---------------------\n",
            "Peek into the file\n",
            "1.2771435232553505\tThat purpose will be fulfilled with the advent of the Lord of the Age (may God hasten his advent).\tاین امر خداوندگار شیوا تا زمان چیتراواهانا جاری است.\n",
            "1.2557609887189667\tEat Within Your Means.\tEat Within Your Means (به انگلیسی).\n",
            "1.2397336646789108\tIt will destroy everything at the bidding of its Lord.\"\tوهمهٔ شکستگی‌ها که کشیدی به سوی خدای خواهدت برد.\n",
            "1.2312599216965339\tAnd this is true of the people of Israel.”\tاین آیه در رابطه با قوم بنی اسرائیل است.\n",
            "1.2261682311095805\tCount from a sign to its lord.\tآنچه را از سوی پروردگارت بر تو نازل شده برسان.\n",
            "1.2228095467220876\tLet them then produce a recital like unto it (the Qur'an) if they are truthful.\tبگو اگر راست می‌گویید سوره‌ای مانند آن را بیاورید».\n",
            "1.2192442297570019\tRecite in the name of your Lord who created—Created man from a clinging substance.\tبخوان به نام پروردگارت که آفرید؛ که انسان را از خون بسته (علق) آفرید.\n",
            "1.2174021303825795\tHe said: My Lord!\t(مؤمنان می‌گویند:) پروردگارا!\n",
            "1.2146066187900746\tBe respectful to your Lord.\tبروید به درگاه خدای خودتان ناله کنید.\n",
            "1.2139046805192228\tWhen this was shown clearly to him, he said: \"I know that God hath power over all things.\"\tپس هنگامی که برای او آشکار شد، گفت: « می‌دانم که خداوند بر هر چیزی تواناست.»\n",
            "---------------------\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "print('Downloading data ...')\n",
        "!wget https://dl.fbaipublicfiles.com/laser/WikiMatrix/v1/WikiMatrix.en-fa.tsv.gz -O data/WikiMatrix.en-fa.tsv.gz\n",
        "print('---------------------')\n",
        "print('Unzipping file ...')\n",
        "!gunzip -k -f data/WikiMatrix.en-fa.tsv.gz\n",
        "print('---------------------')\n",
        "print('Peek into the file')\n",
        "!head -10 data/WikiMatrix.en-fa.tsv\n",
        "print('---------------------')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('File length ...')\n",
        "!wc -l data/WikiMatrix.en-fa.tsv\n",
        "print('---------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0-Srw5cIlUt",
        "outputId": "650e5f20-b9f6-4b88-f328-d4966d3cbecc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File length ...\n",
            "1128507 data/WikiMatrix.en-fa.tsv\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LASER CONFIDENCE**\n",
        "\n",
        "LASER is a multi-lingual neural sentence embedding model that is often used for cross-lingual sentence/document retrieval. Similarities in the embedding space are often used as proxies for cross-lingual similarities"
      ],
      "metadata": {
        "id": "Q-0Tv1nHJBqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def num_lines_in_file(fname):\n",
        "    \"\"\"\n",
        "    Returns the number of lines in a file.\n",
        "    \"\"\"\n",
        "    with open(fname, 'r') as f:\n",
        "        for i, _ in enumerate(f):\n",
        "            pass\n",
        "    return i + 1\n",
        "\n",
        "def filter_tsv_with_conf(\n",
        "    input_file, output_file_lang_1, output_file_lang_2,\n",
        "    confidence_threshold=None, confidence_column=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Filters a tsv file that has confidence scores associated with each parallel example.\n",
        "\n",
        "    For example:\n",
        "\n",
        "    1.23 \\t This is a sentence in lang1 \\t This is a sentence in lang2\n",
        "    \"\"\"\n",
        "    print()\n",
        "    print('====================================')\n",
        "    print('======= TSV Conf Filtering =========')\n",
        "    print('====================================')\n",
        "    print()\n",
        "    num_lines = num_lines_in_file(input_file)\n",
        "    scores = []\n",
        "    num_output_lines = 0\n",
        "    lang_1_col = 0\n",
        "    lang_2_col = 1\n",
        "    with open(input_file, 'r') as f, \\\n",
        "        open(output_file_lang_1, 'w') as f_out_1, \\\n",
        "        open(output_file_lang_2, 'w') as f_out_2:\n",
        "        for line in tqdm(f, total=num_lines, desc=f\"Filtering file by confidence {confidence_threshold}\"):\n",
        "            if line.strip() == '':\n",
        "                continue\n",
        "            line = line.strip().split('\\t')\n",
        "            if len(line) < 2:\n",
        "                continue\n",
        "            if confidence_threshold is not None and float(line[confidence_column]) < confidence_threshold:\n",
        "                continue\n",
        "            else:\n",
        "                if confidence_threshold is not None:\n",
        "                    scores.append(float(line[confidence_column]))\n",
        "                    if confidence_column == 0:\n",
        "                        lang_1_col, lang_2_col = 1, 2\n",
        "                    elif confidence_column == 2:\n",
        "                        lang_1_col, lang_2_col = 0, 1\n",
        "                    elif confidence_column == 1:\n",
        "                        lang_1_col, lang_2_col = 0, 2\n",
        "                    else:\n",
        "                        raise ValueError(f\"Invalid Column for confidence {confidence_column}\")\n",
        "                f_out_1.write(line[lang_1_col] + '\\n')\n",
        "                f_out_2.write(line[lang_2_col] + '\\n')\n",
        "                num_output_lines += 1\n",
        "\n",
        "    if confidence_threshold is not None:\n",
        "        print(f'Confidence score average  : {np.mean(scores)}')\n",
        "        print(f'Confidence score variance : {np.var(scores)}')\n",
        "        print(f'Kept {num_output_lines} out of {num_lines} after conversion ({(num_output_lines / num_lines) * 100}%)')\n",
        "        print('====================================')\n",
        "\n",
        "filter_tsv_with_conf(\n",
        "    'data/WikiMatrix.en-fa.tsv',\n",
        "    'data/WikiMatrix.en-fa.en',\n",
        "    'data/WikiMatrix.en-fa.fa',\n",
        "    confidence_threshold=1.04, confidence_column=0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuR-TjrUIrUV",
        "outputId": "e439e435-30b5-4252-c805-120f497cc115"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================\n",
            "======= TSV Conf Filtering =========\n",
            "====================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Filtering file by confidence 1.04: 100%|██████████| 1128507/1128507 [00:05<00:00, 191646.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence score average  : 1.0574949045215685\n",
            "Confidence score variance : 0.0002476336996916896\n",
            "Kept 303805 out of 1128507 after conversion (26.920967260282836%)\n",
            "====================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Language ID filtering**\n",
        "\n",
        "Noisy parallel corpora often contain sentences that are not in the intended language. A classifier that determines the language in which a sentence is written can be used to filter out sentences that aren't in the appropriate language"
      ],
      "metadata": {
        "id": "ecLY8JRbJ0gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H3TIkWhJ7z8",
        "outputId": "a0367093-552a-4888-9336-0904857f1acd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199771 sha256=274c296e50738dc00c7e0f96398a2b0a3456abb63188a71ae60fbdf43bbda03b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin -O data/lid.176.bin\n",
        "print()\n",
        "print('====================================')\n",
        "print('====== Language ID Filtering =======')\n",
        "print('====================================')\n",
        "print()\n",
        "\n",
        "\n",
        "!wget https://raw.github.com/NVIDIA/NeMo/main/scripts/neural_machine_translation/filter_langs_nmt.py \\\n",
        "    -O filter_langs_nmt.py\n",
        "\n",
        "!python filter_langs_nmt.py \\\n",
        "    --input-src data/WikiMatrix.en-fa.en  \\\n",
        "    --input-tgt data/WikiMatrix.en-fa.fa \\\n",
        "    --output-src data/WikiMatrix.en-fa.langidfilter.en  \\\n",
        "    --output-tgt data/WikiMatrix.en-fa.langidfilter.fa  \\\n",
        "    --source-lang en \\\n",
        "    --target-lang fa \\\n",
        "    --removed-src data/WikiMatrix.en-fa.langidfilter.removed.en  \\\n",
        "    --removed-tgt data/WikiMatrix.en-fa.langidfilter.removed.fa  \\\n",
        "    --fasttext-model data/lid.176.bin\n",
        "\n",
        "print()\n",
        "print('-----------------------------------------')\n",
        "print('Number of removed sentences:')\n",
        "print('-----------------------------------------')\n",
        "print()\n",
        "!wc -l data/WikiMatrix.en-fa.langidfilter.removed.fa\n",
        "\n",
        "print()\n",
        "print('-----------------------------------------')\n",
        "print('Examples of removed sentences')\n",
        "print('-----------------------------------------')\n",
        "print()\n",
        "\n",
        "!paste -d \"\\t\" \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.removed.en \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.removed.fa \\\n",
        "    | head -10\n",
        "print('-----------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2Y32QZeLdhx",
        "outputId": "5f69f56d-5add-48e8-e133-9fe0bea56f4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-06 04:39:59--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.173.166.48, 18.173.166.31, 18.173.166.74, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.173.166.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131266198 (125M) [application/octet-stream]\n",
            "Saving to: ‘data/lid.176.bin’\n",
            "\n",
            "data/lid.176.bin    100%[===================>] 125.18M   110MB/s    in 1.1s    \n",
            "\n",
            "2023-11-06 04:40:00 (110 MB/s) - ‘data/lid.176.bin’ saved [131266198/131266198]\n",
            "\n",
            "\n",
            "====================================\n",
            "====== Language ID Filtering =======\n",
            "====================================\n",
            "\n",
            "--2023-11-06 04:40:00--  https://raw.github.com/NVIDIA/NeMo/main/scripts/neural_machine_translation/filter_langs_nmt.py\n",
            "Resolving raw.github.com (raw.github.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.github.com (raw.github.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/neural_machine_translation/filter_langs_nmt.py [following]\n",
            "--2023-11-06 04:40:00--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/neural_machine_translation/filter_langs_nmt.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14737 (14K) [text/plain]\n",
            "Saving to: ‘filter_langs_nmt.py’\n",
            "\n",
            "filter_langs_nmt.py 100%[===================>]  14.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-06 04:40:00 (30.2 MB/s) - ‘filter_langs_nmt.py’ saved [14737/14737]\n",
            "\n",
            "processed lines / total number of lines: 100% 303525/303805 [00:56<00:00, 5371.88it/s]\n",
            "\n",
            "-----------------------------------------\n",
            "Number of removed sentences:\n",
            "-----------------------------------------\n",
            "\n",
            "6355 data/WikiMatrix.en-fa.langidfilter.removed.fa\n",
            "\n",
            "-----------------------------------------\n",
            "Examples of removed sentences\n",
            "-----------------------------------------\n",
            "\n",
            "Opsaridium ubangiense.\tنام خدای آن‌ها (بالاترین مرتبه ربانی) یزدان است.\n",
            "\"CNTO China Like Never Before\".\tCNTO China Like Never Before (به انگلیسی).\n",
            "Οικουμενικό Πατριαρχείο Πανδέκτης\tآغاز وحی ۴.\n",
            "\"தாய் மீது சத்தியம் தமிழ் திரைப்படம்\" (in Tamil).\tسرود قَسَماً (به معنی: سوگند یاد می‌کنیم) سرود ملی کشور الجزایر است.\n",
            "\"پشت دیوار کیه؟ رپ ایرانی؟\".\t«پشت دیوار کیه؟ رپ ایرانی؟».\n",
            "\"Muarem Muarem rəsmən \"Qarabağ\"da!\".\tاین راه تحت تأثیر قرار دادن پروردگار من کودالا سنگام دوا است.\n",
            "\"قلم چی: با حقوق معلمی شروع کردم\".\t«قلم چی: با حقوق معلمی شروع کردم».\n",
            "دختری از بلاروس که بوشهری شد .\tدختری از بلاروس که بوشهری شد.\n",
            "\"130 شرکت تولیدی صنعتی با حمایت بنیاد برکت تأسیس شد\".\t\"130 شرکت تولیدی صنعتی با حمایت بنیاد برکت تأسیس شد\".\n",
            "\"آیت‌الله ملکوتی دار فانی را وداع گفت\".\t«آیت الله ابطحی کاشانی دار فانی را وداع گفت».\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Length and Ratio Filtering**\n",
        "\n",
        "This step filters out sentences based on their lengths and the ratio between source and target lengths. If (a) src_len / tgt_len or tgt_len / src_len exceed 1.3 or (b) source or target sequence lengths are less than 1 or greater than 250, the sentence pair will be removed"
      ],
      "metadata": {
        "id": "oWurN1miNEPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/moses-smt/mosesdecoder data/mosesdecoder\n",
        "!cd data/mosesdecoder\n",
        "!git checkout RELEASE-4.0 && cd ../..\n",
        "!perl data/mosesdecoder/scripts/training/clean-corpus-n.perl -ratio 1.3 \\\n",
        "    data/WikiMatrix.en-fa.langidfilter \\\n",
        "    en fa \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio \\\n",
        "    1 250"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdORxq3tNCiR",
        "outputId": "c6ac10ef-fff0-4040-ffc8-187f5ba71959"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data/mosesdecoder' already exists and is not an empty directory.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "clean-corpus.perl: processing data/WikiMatrix.en-fa.langidfilter.en & .fa to data/WikiMatrix.en-fa.langidfilter.lengthratio, cutoff 1-250, ratio 1.3\n",
            "..........(100000)..........(200000).........\n",
            "Input sentences: 297450  Output sentences:  220337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize Punctuation**\n",
        "\n",
        "Punctuation can vary across languages and even between ascii and unicode variants of the same punctuation marker. For example, across languages. For example, in German, quotes are often written as „ and “ while in English we typically just use \". This step normalizes such punctuation differences to use the same character everywhere."
      ],
      "metadata": {
        "id": "2z2DvaKiU_Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeKK_rjnVkmW",
        "outputId": "97e65fff-749d-42d8-8e7e-02d70d0f3739"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m553.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184347 sha256=434a3ee2beeb7b5ae8c5382c0e8a1d008df144fbd14020e17649fe52ef81ce9a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dvz8cemz/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!apt-get install libboost-all-dev\n",
        "!apt-get install gawk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaKGAM3ZWSFv",
        "outputId": "294b027c-fa92-4170-ff08-0858c04c6d29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=a4c131622c71a24d29c37be43348d73bb6dcc1680ceef7a40b640a3404d5ff2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libboost-all-dev is already the newest version (1.74.0.3ubuntu7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  gawk-doc\n",
            "The following NEW packages will be installed:\n",
            "  gawk\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 447 kB of archives.\n",
            "After this operation, 1,720 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gawk amd64 1:5.1.0-1ubuntu0.1 [447 kB]\n",
            "Fetched 447 kB in 0s (1,761 kB/s)\n",
            "Selecting previously unselected package gawk.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../gawk_1%3a5.1.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking gawk (1:5.1.0-1ubuntu0.1) ...\n",
            "Setting up gawk (1:5.1.0-1ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libsndfile1 ffmpeg\n",
        "!git clone https://github.com/NVIDIA/NeMo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY2uo7QDWVPp",
        "outputId": "f71a5e88-fed4-4968-df95-f4acaa3bee4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [Connected to cloud.r-\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r0% [2 InRelease 12.7 kB/119 kB 11%] [Connecting to security.ubuntu.com (185.125.190.39)] [Connected \r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [2 InRelease 21.4 kB/119 kB 18%] [Waiting for headers] [Waiting for headers] [Connecting to ppa.l\r                                                                                                    \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [46.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,419 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,231 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,145 kB]\n",
            "Fetched 5,251 kB in 4s (1,342 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.31-2ubuntu0.1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Cloning into 'NeMo'...\n",
            "remote: Enumerating objects: 133750, done.\u001b[K\n",
            "remote: Counting objects: 100% (2113/2113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1217/1217), done.\u001b[K\n",
            "remote: Total 133750 (delta 1231), reused 1634 (delta 876), pack-reused 131637\u001b[K\n",
            "Receiving objects: 100% (133750/133750), 237.13 MiB | 22.91 MiB/s, done.\n",
            "Resolving deltas: 100% (99534/99534), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd NeMo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKQLfK_FWX4S",
        "outputId": "792b56be-e90c-42db-f9d4-c837039398f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NeMo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash ./reinstall.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFTl4k6lWc1F",
        "outputId": "62326d22-481f-489c-c58f-60fb468fcb8f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n",
            "Uninstalling stuff\n",
            "\u001b[33mWARNING: Skipping nemo_toolkit as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping sacrebleu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping nemo_asr as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping nemo_nlp as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping nemo_tts as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling nemo\n",
            "Obtaining file:///content/NeMo\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.56.4)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting onnx>=1.7.0\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.14.1)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Collecting black==19.10b0\n",
            "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click==8.0.2\n",
            "  Downloading click-8.0.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort<6.0.0,>5.1.0\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parameterized\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.4.3)\n",
            "Collecting pytest-runner\n",
            "  Downloading pytest_runner-6.0.0-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.10/dist-packages (5.0.2)\n",
            "Collecting sphinxcontrib-bibtex\n",
            "  Downloading sphinxcontrib_bibtex-2.6.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.12-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting hydra-core<=1.3.2,>1.3\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<=2.3\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning<=2.0.7,>=2.0\n",
            "  Downloading pytorch_lightning-2.0.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting torchmetrics>=0.11.0\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting transformers<=4.33.3,>=4.0.1\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl.metadata (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webdataset<=0.1.62,>=0.1.48\n",
            "  Downloading webdataset-0.1.62-py3-none-any.whl (32 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (7.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (1.10.13)\n",
            "Collecting sacremoses>=0.0.43\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting sentencepiece<1.0.0\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting youtokentome>=1.0.5\n",
            "  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Collecting g2p-en\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kaldi-python-io\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kaldiio\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Collecting marshmallow\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.2)\n",
            "Collecting pyannote.core\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.metrics\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (1.11.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting texterrors\n",
            "  Downloading texterrors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.28.78-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Collecting flask-restful\n",
            "  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Collecting ijson\n",
            "  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (0.42.1)\n",
            "Collecting markdown2\n",
            "  Downloading markdown2-2.4.10-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting megatron-core==0.3.0\n",
            "  Downloading megatron_core-0.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting opencc<1.1.7\n",
            "  Downloading OpenCC-1.1.6-cp310-cp310-manylinux1_x86_64.whl (778 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.3/778.3 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pangu\n",
            "  Downloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorstore<0.1.46 in /usr/local/lib/python3.10/dist-packages (0.1.45)\n",
            "Collecting zarr\n",
            "  Downloading zarr-2.16.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.7.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pypinyin-dict\n",
            "  Downloading pypinyin_dict-0.6.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting progress>=1.5\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Collecting textdistance>=4.1.5\n",
            "  Downloading textdistance-4.6.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nemo-text-processing\n",
            "  Downloading nemo_text_processing-0.2.2rc0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.10/dist-packages (from black==19.10b0) (23.1.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from black==19.10b0) (1.4.4)\n",
            "Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.10/dist-packages (from black==19.10b0) (0.10.2)\n",
            "Collecting typed-ast>=1.4.0 (from black==19.10b0)\n",
            "  Downloading typed_ast-1.5.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from black==19.10b0) (2023.6.3)\n",
            "Collecting pathspec<1,>=0.6 (from black==19.10b0)\n",
            "  Downloading pathspec-0.11.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<=1.3.2,>1.3)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n",
            "  Downloading jiwer-3.0.0-py3-none-any.whl (21 kB)\n",
            "  Downloading jiwer-2.6.0-py3-none-any.whl (20 kB)\n",
            "  Downloading jiwer-2.5.2-py3-none-any.whl (15 kB)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0) (1.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.39.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<=2.3) (6.0.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.7.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil) (1.16.0)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<=2.0.7,>=2.0) (2023.6.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning<=2.0.7,>=2.0)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.33.3,>=4.0.1) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<=4.33.3,>=4.0.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<=4.33.3,>=4.0.1)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.32.0,>=1.31.78 (from boto3)\n",
            "  Downloading botocore-1.31.78-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Collecting aniso8601>=0.82 (from flask-restful)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-restful) (2.2.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from flask-restful) (2023.3.post1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.8)\n",
            "Collecting distance>=0.1.3 (from g2p-en)\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.9)\n",
            "Collecting cdifflib (from nemo-text-processing)\n",
            "  Downloading cdifflib-1.2.6.tar.gz (11 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynini==2.1.5 (from nemo-text-processing)\n",
            "  Downloading pynini-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from pynini==2.1.5->nemo-text-processing) (3.0.4)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core) (2.4.0)\n",
            "Collecting pyannote.database>=4.0.1 (from pyannote.metrics)\n",
            "  Downloading pyannote.database-5.0.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6.2 (from pyannote.metrics)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx) (1.4.1)\n",
            "Collecting docutils<0.19,>=0.14 (from sphinx)\n",
            "  Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybtex>=0.24 (from sphinxcontrib-bibtex)\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybtex-docutils>=1.0.0 (from sphinxcontrib-bibtex)\n",
            "  Downloading pybtex_docutils-1.0.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Collecting plac (from texterrors)\n",
            "  Downloading plac-1.4.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting loguru (from texterrors)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from texterrors) (2.3.0)\n",
            "Collecting Levenshtein (from texterrors)\n",
            "  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting asciitree (from zarr)\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasteners (from zarr)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting numcodecs>=0.10.0 (from zarr)\n",
            "  Downloading numcodecs-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.78->boto3) (2.0.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-restful) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.39)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0) (3.11.0)\n",
            "Requirement already satisfied: typer>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics) (0.9.0)\n",
            "Collecting latexcodec>=1.0.4 (from pybtex>=0.24->sphinxcontrib-bibtex)\n",
            "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.33.3,>=4.0.1) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.33.3,>=4.0.1) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "INFO: pip is looking at multiple versions of levenshtein to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting Levenshtein (from texterrors)\n",
            "  Downloading Levenshtein-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.4.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics) (13.6.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.18.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.19.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics) (3.0.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.6)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics) (0.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Downloading megatron_core-0.3.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.5/194.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.0.7-py3-none-any.whl (724 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textdistance-4.6.0-py3-none-any.whl (31 kB)\n",
            "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.28.78-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n",
            "Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.4.10-py2.py3-none-any.whl (39 kB)\n",
            "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nemo_text_processing-0.2.2rc0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin_dict-0.6.0-py2.py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_bibtex-2.6.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-2.16.1-py3-none-any.whl (206 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.9/206.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.31.78-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Downloading numcodecs-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Downloading pybtex_docutils-1.0.3-py3-none-any.whl (6.4 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typed_ast-1.5.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.7/824.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading Levenshtein-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.9/172.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plac-1.4.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: antlr4-python3-runtime, progress, youtokentome, kaldi-python-io, nemo-toolkit, rouge-score, sentence-transformers, distance, docopt, asciitree, cdifflib, pathtools\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=a82cb48c37b8d6040375110f9e61dc0925f1725ee91a051d0bc78c249ba717d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9610 sha256=156c20ddf217908678f7f98b300e315ddc79fc9709d3c125f8a481587cfa853b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/68/5f/c339b20a41659d856c93ccdce6a33095493eb82c3964aac5a1\n",
            "  Building wheel for youtokentome (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp310-cp310-linux_x86_64.whl size=1951066 sha256=a1e04421b0560b0f6d59ffa896732b370455b0bb8c129305e2d3ab662013aa77\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/85/f8/301d2ba45f43f30bed2fe413efa760bc726b8b660ed9c2900c\n",
            "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8948 sha256=7c4b4c5c8fad663be39b1be6b81ba137dd4ad96cf35db9d67cc3219fa7f41eef\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/23/5f/49d3a826be576faf61d84e8028e1914bb36a5586ee2613b087\n",
            "  Building editable for nemo-toolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nemo-toolkit: filename=nemo_toolkit-1.21.0rc0-0.editable-py3-none-any.whl size=9256 sha256=baf0437e471fd5e0f0c298125397fcc6917403f42c555db462b9b13204bfd257\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ncmmd4u8/wheels/41/a7/71/00ccdddfb43c015e8d025853cafb90117dd722fd8ec557581b\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=69c49630ec8d48e973f82d825b241b406c492e9779ce727efdc9534954f746b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=26f56718649f1dc82c98fe4c3c3930da80e675268994aef2c36e5ca665d19b17\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=f9a9310928cf8cb94e32db5c21a47af586910fbd5612e7c3117029909ffbb124\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=7f35defaa87e4ef43f9859bad28bef6ca89569e35ee82b31d9f8a5627126a74d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5034 sha256=a88622415bcd3cb558c01a1c4f7bc57ff59c1406a0f7910ca1339abae95826ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\n",
            "  Building wheel for cdifflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cdifflib: filename=cdifflib-1.2.6-cp310-cp310-linux_x86_64.whl size=27676 sha256=ab21b67f6fbbd6f64e6d86ba09054437393fc3757c8a65c35cb0aac4bc509f78\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/a7/fd/8061e24ed08689045cb6d1ca303768dc463b20a5a338174841\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=186b4d842ae4da0c0de494f44d2544bae4477f00e88d6569394cd15295d0e360\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built antlr4-python3-runtime progress youtokentome kaldi-python-io nemo-toolkit rouge-score sentence-transformers distance docopt asciitree cdifflib pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, pydub, progress, plac, pathtools, pangu, opencc, megatron-core, ijson, faiss-cpu, docopt, distance, braceexpand, asciitree, antlr4-python3-runtime, aniso8601, webdataset, typed-ast, textdistance, sox, smmap, shellingham, setproctitle, sentry-sdk, safetensors, ruamel.yaml.clib, rapidfuzz, pytest-runner, pypinyin, pynini, portalocker, pathspec, parameterized, onnx, omegaconf, numcodecs, marshmallow, markdown2, loguru, lightning-utilities, latexcodec, kaldiio, kaldi-python-io, jmespath, jedi, isort, ftfy, fasteners, einops, docutils, docker-pycreds, dill, colorama, click, cdifflib, attrdict, zarr, youtokentome, sacremoses, sacrebleu, ruamel.yaml, pypinyin-dict, pybtex, pyannote.core, multiprocess, Levenshtein, jiwer, hydra-core, huggingface-hub, gitdb, botocore, black, transformers, torchmetrics, texterrors, s3transfer, rouge-score, pybtex-docutils, kornia, GitPython, g2p-en, flask-restful, wandb, sentence-transformers, pytorch-lightning, pyannote.database, nemo-text-processing, datasets, boto3, pyannote.metrics, nemo-toolkit, sphinxcontrib-bibtex\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 Levenshtein-0.22.0 aniso8601-9.0.1 antlr4-python3-runtime-4.9.3 asciitree-0.3.3 attrdict-2.0.1 black-19.10b0 boto3-1.28.78 botocore-1.31.78 braceexpand-0.1.7 cdifflib-1.2.6 click-8.0.2 colorama-0.4.6 datasets-2.14.6 dill-0.3.7 distance-0.1.3 docker-pycreds-0.4.0 docopt-0.6.2 docutils-0.17.1 einops-0.7.0 faiss-cpu-1.7.4 fasteners-0.19 flask-restful-0.3.10 ftfy-6.1.1 g2p-en-2.1.0 gitdb-4.0.11 huggingface-hub-0.18.0 hydra-core-1.3.2 ijson-3.2.3 isort-5.12.0 jedi-0.19.1 jiwer-2.5.2 jmespath-1.0.1 kaldi-python-io-1.2.2 kaldiio-2.18.0 kornia-0.7.0 latexcodec-2.0.1 lightning-utilities-0.9.0 loguru-0.7.2 markdown2-2.4.10 marshmallow-3.20.1 megatron-core-0.3.0 multiprocess-0.70.15 nemo-text-processing-0.2.2rc0 nemo-toolkit-1.21.0rc0 numcodecs-0.12.1 omegaconf-2.3.0 onnx-1.15.0 opencc-1.1.6 pangu-4.0.6.1 parameterized-0.9.0 pathspec-0.11.2 pathtools-0.1.2 plac-1.4.1 portalocker-2.8.2 progress-1.6 pyannote.core-5.0.0 pyannote.database-5.0.1 pyannote.metrics-3.2.1 pybtex-0.24.0 pybtex-docutils-1.0.3 pydub-0.25.1 pynini-2.1.5 pypinyin-0.49.0 pypinyin-dict-0.6.0 pytest-runner-6.0.0 pytorch-lightning-2.0.7 rapidfuzz-2.13.7 rouge-score-0.1.2 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8 s3transfer-0.7.0 sacrebleu-2.3.1 sacremoses-0.1.1 safetensors-0.4.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 sentry-sdk-1.34.0 setproctitle-1.3.3 shellingham-1.5.4 smmap-5.0.1 sox-1.4.1 sphinxcontrib-bibtex-2.6.1 textdistance-4.6.0 texterrors-0.4.4 tokenizers-0.13.3 torchmetrics-1.2.0 transformers-4.33.3 typed-ast-1.5.5 wandb-0.15.12 webdataset-0.1.62 youtokentome-1.0.6 zarr-2.16.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mAll done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adBYK7yTXVYj",
        "outputId": "d5b38c3d-418f-4803-bd9c-4b5a9fa6a836"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sacremoses**"
      ],
      "metadata": {
        "id": "qX1iXnsLVJQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Normalizing English ...')\n",
        "!sacremoses -j 4 normalize \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.en > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.sacremoses.norm.en\n",
        "\n",
        "print('Normalizing Farsi ...')\n",
        "!sacremoses -j 4 normalize \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.fa > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.sacremoses.norm.fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u317Ija3OMca",
        "outputId": "46297e56-0f42-4fac-d5a5-a57d6a92ea68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizing English ...\n",
            "100% 220337/220337 [00:26<00:00, 8421.19it/s] \n",
            "Normalizing Farsi ...\n",
            "100% 220337/220337 [00:29<00:00, 7377.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moses**"
      ],
      "metadata": {
        "id": "hSeX33Y5X0Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Normalizing English ...')\n",
        "!perl data/mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -l en \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.en > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.en\n",
        "\n",
        "print('Normalizing Farsi ...')\n",
        "!perl data/mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -l fa \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.fa > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeSjvj_zX25R",
        "outputId": "45d1332a-02ca-4506-e648-4f326fd74bc2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizing English ...\n",
            "Normalizing Farsi ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenize**\n",
        "\n",
        "\"This is a sentence.\" will be tokenized as [\"This, is, a, sentence.\"].\n",
        "\n",
        "However, we'd typically like punctuation to be separate tokens for example,\n",
        "\n",
        "\"This is a sentence.\" will be tokenized my moses or sacremoses as [\", This, is, a, sentence, ., \"]."
      ],
      "metadata": {
        "id": "ymTqHbHbYRty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sacremoses**"
      ],
      "metadata": {
        "id": "2kZsZw-kYdgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenizing English ...')\n",
        "!sacremoses -j 4 -l en tokenize -x \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.sacremoses.norm.en > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.sacremoses.norm.tok.en\n",
        "\n",
        "print('Tokenizing Farsi ...')\n",
        "!sacremoses -j 4 -l fa tokenize -x \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.sacremoses.norm.fa > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.sacremoses.norm.tok.fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgMEI3oHYbg1",
        "outputId": "711a0841-e1bd-430b-e1ee-386f55d1a818"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing English ...\n",
            "100% 220337/220337 [00:49<00:00, 4473.27it/s]\n",
            "Tokenizing Farsi ...\n",
            "100% 220337/220337 [00:33<00:00, 6573.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moses**"
      ],
      "metadata": {
        "id": "7zNqh1NvYkn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenizing English ...')\n",
        "!perl data/mosesdecoder/scripts/tokenizer/tokenizer.perl -l en -no-escape -threads 4 \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.en > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.en\n",
        "\n",
        "print('Tokenizing Farsi ...')\n",
        "!perl data/mosesdecoder/scripts/tokenizer/tokenizer.perl -l fa -no-escape -threads 4 \\\n",
        "    < data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.fa > \\\n",
        "    data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Yp2WWBYoxC",
        "outputId": "d154a066-9cad-4c1c-949d-7432ca584751"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing English ...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 4\n",
            "Tokenizing Farsi ...\n",
            "Tokenizer Version 1.1\n",
            "Language: fa\n",
            "Number of threads: 4\n",
            "WARNING: No known abbreviations for language 'fa', attempting fall-back to English version...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print('-----------------------------------------')\n",
        "print('Tokenized Farsi Sentences ...')\n",
        "print('-----------------------------------------')\n",
        "print()\n",
        "\n",
        "!head -10 data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.fa\n",
        "\n",
        "print()\n",
        "print('-----------------------------------------')\n",
        "print('Tokenized English Sentences ...')\n",
        "print('-----------------------------------------')\n",
        "print()\n",
        "\n",
        "!head -10 data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZkuOvKBZlm5",
        "outputId": "fd3e7c55-427a-4841-8315-9f9ad6d6afa6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------------\n",
            "Tokenized Farsi Sentences ...\n",
            "-----------------------------------------\n",
            "\n",
            "وهمهٔ شکستگی ‌ ها که کشیدی به سوی خدای خواهدت برد .\n",
            "این آیه در رابطه با قوم بنی اسرائیل است .\n",
            "بخوان به نام پروردگارت که آفرید ؛ که انسان را از خون بسته ( علق ) آفرید .\n",
            "پس هنگامی که برای او آشکار شد ، گفت : \" می ‌ دانم که خداوند بر هر چیزی تواناست \" .\n",
            "در ربّنای شجریان ، هر آیه از ابتدای ربّنا تا آخر آیه خوانده می ‌ شود .\n",
            "او با نام رب ‌ السیف و القلم ( پروردگار شمشیر و قلم ) نیز شناخته می ‌ شود .\n",
            "بخوان به نام پروردگارت که آفرید .\n",
            "ابراهیم در نجف عالم می شوند ولی علی اکبر به سار بر می گردند .\n",
            "دلایل روشنی از طرف پروردگار برای شما آمده .\n",
            "پس این امور هم یقینی هستند .\n",
            "\n",
            "-----------------------------------------\n",
            "Tokenized English Sentences ...\n",
            "-----------------------------------------\n",
            "\n",
            "It will destroy everything at the bidding of its Lord . \"\n",
            "And this is true of the people of Israel . \"\n",
            "Recite in the name of your Lord who created - Created man from a clinging substance .\n",
            "When this was shown clearly to him , he said : \" I know that God hath power over all things . \"\n",
            "He to whom the Lord giveth victory prevails over all ( mankind ) .\n",
            "Eltab is known as the Lord of the Hidden Layer .\n",
            "Read , for your Lord is most beneficent .\n",
            "Abraham is gone but he will return to them as they still have Ike .\n",
            "There has come to you clear evidence from your Lord .\n",
            "And that is the Religion of Truth . \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deduplicate**\n",
        "\n",
        " This step removes duplicate translation pairs from the corpus"
      ],
      "metadata": {
        "id": "vs2b1EjiZuPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xxhash\n",
        "\n",
        "def dedup_file(input_file_lang_1, input_file_lang_2, output_file_lang_1, output_file_lang_2):\n",
        "    print()\n",
        "    print('====================================')\n",
        "    print('========== De-duplicate ============')\n",
        "    print('====================================')\n",
        "    print()\n",
        "    num_lines = num_lines_in_file(input_file_lang_1)\n",
        "    hashes = set()\n",
        "    num_output_lines = 0\n",
        "    with open(input_file_lang_1, 'r') as f_lang1, \\\n",
        "        open(input_file_lang_2, 'r')  as f_lang2, \\\n",
        "        open(output_file_lang_1, 'w') as f_out_lang1, \\\n",
        "        open(output_file_lang_2, 'w') as f_out_lang2:\n",
        "        for line_1, line_2 in tqdm(zip(f_lang1, f_lang2), total=num_lines, desc=f\"Deduplicating files\"):\n",
        "            parallel_hash = xxhash.xxh64((line_1.strip() + '\\t' + line_2.strip()).encode('utf-8')).hexdigest()\n",
        "            if parallel_hash not in hashes:\n",
        "                hashes.add(parallel_hash)\n",
        "                f_out_lang1.write(line_1.strip() + '\\n')\n",
        "                f_out_lang2.write(line_2.strip() + '\\n')\n",
        "                num_output_lines += 1\n",
        "\n",
        "    print(f\"Kept {num_output_lines} out of {num_lines} after deduplication\")\n",
        "\n",
        "dedup_file(\n",
        "    'data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.en',\n",
        "    'data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.fa',\n",
        "    'data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.dedup.en',\n",
        "    'data/WikiMatrix.en-fa.langidfilter.lengthratio.moses.norm.tok.dedup.fa'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jicKeJifZwgB",
        "outputId": "b4884b4d-c3f7-49fe-cf8d-2cff9266666c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================\n",
            "========== De-duplicate ============\n",
            "====================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deduplicating files: 100%|██████████| 220337/220337 [00:01<00:00, 154208.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kept 220337 out of 220337 after deduplication\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "folder_path = '/content/data'\n",
        "output_zip_path = '/content/data.zip'\n",
        "\n",
        "shutil.make_archive(output_zip_path.split('.zip')[0], 'zip', folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xlPxwQusbsjc",
        "outputId": "d9903d72-1969-416d-81f1-2e0f1579123e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/data.zip' '/content/drive/MyDrive/Colab Notebooks'"
      ],
      "metadata": {
        "id": "zodLZyijbMUI"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}